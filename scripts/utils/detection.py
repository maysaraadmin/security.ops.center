""\nEDR Detection Engine - Threat Detection and Analysis\n\nThis module implements the detection engine for the EDR system,\nwhich analyzes events and detects potential security threats.\n"""\n\nimport re\nimport time\nimport json\nimport logging\nimport yara\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional, Any, Callable, Pattern\nfrom dataclasses import dataclass, field\nimport hashlib\nimport os\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('edr_detection.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger('edr.detection')\n\n@dataclass\nclass DetectionRule:\n    """Represents a detection rule for identifying threats."""\n    id: str\n    name: str\n    description: str\n    severity: str  # info, low, medium, high, critical\n    enabled: bool = True\n    tags: List[str] = field(default_factory=list)\n    condition: Optional[str] = None\n    yara_rule: Optional[str] = None\n    yara_compiled: Any = None\n    regex_patterns: List[Dict[str, str]] = field(default_factory=list)\n    compiled_regex: List[Pattern] = field(default_factory=list)\n    event_types: List[str] = field(default_factory=list)\n    threshold: Optional[int] = None\n    time_window: Optional[int] = None  # in seconds\n    actions: List[str] = field(default_factory=list)\n    false_positives: List[str] = field(default_factory=list)\n    references: List[str] = field(default_factory=list)\n    author: str = ""\n    created: str = field(default_factory=lambda: datetime.utcnow().isoformat())\n    updated: str = field(default_factory=lambda: datetime.utcnow().isoformat())\n    \n    def __post_init__(self):\n        """Compile YARA rules and regex patterns after initialization."""\n        # Compile YARA rule if provided\n        if self.yara_rule and not self.yara_compiled:\n            try:\n                self.yara_compiled = yara.compile(source=self.yara_rule)\n            except yara.SyntaxError as e:\n                logger.error(f"Error compiling YARA rule {self.id}: {e}")\n                self.enabled = False\n        \n        # Compile regex patterns\n        self.compiled_regex = []\n        for pattern in self.regex_patterns:\n            try:\n                flags = 0\n                if pattern.get('case_insensitive', True):\n                    flags |= re.IGNORECASE\n                if pattern.get('multiline', False):\n                    flags |= re.MULTILINE\n                \n                compiled = re.compile(pattern['pattern'], flags)\n                self.compiled_regex.append({\n                    'compiled': compiled,\n                    'field': pattern.get('field', ''),\n                    'description': pattern.get('description', '')\n                })\n            except re.error as e:\n                logger.error(f"Error compiling regex in rule {self.id}: {e}")\n    \n    def to_dict(self) -> Dict[str, Any]:\n        """Convert the rule to a dictionary."""\n        result = {k: v for k, v in self.__dict__.items() if k != 'yara_compiled' and k != 'compiled_regex'}\n        result['compiled_regex'] = [p['pattern'] for p in self.regex_patterns]\n        return result\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'DetectionRule':\n        """Create a DetectionRule from a dictionary."""\n        return cls(**data)\n    \n    def match(self, event: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n        """\n        Check if the rule matches the given event.\n        \n        Returns:\n            Dict with match details if the rule matches, None otherwise.\n        """\n        if not self.enabled:\n            return None\n        \n        # Check event type filter\n        if self.event_types and event.get('event_type') not in self.event_types:\n            return None\n        \n        matches = {\n            'rule_id': self.id,\n            'rule_name': self.name,\n            'severity': self.severity,\n            'timestamp': datetime.utcnow().isoformat(),\n            'matches': []\n        }\n        \n        # Check YARA rule if present\n        if self.yara_compiled and 'data' in event:\n            try:\n                if isinstance(event['data'], dict):\n                    # Convert dict to string for YARA scanning\n                    data_str = json.dumps(event['data'])\n                    if self.yara_compiled.match(data=data_str):\n                        matches['matches'].append({\n                            'type': 'yara',\n                            'description': 'Matched YARA rule'\n                        })\n            except Exception as e:\n                logger.error(f"Error applying YARA rule {self.id}: {e}")\n        \n        # Check regex patterns\n        for pattern in self.compiled_regex:\n            try:\n                field = pattern['field']\n                if not field:  # If no field specified, check all string fields\n                    for key, value in event.items():  \n                        if isinstance(value, str):\n                            if pattern['compiled'].search(value):\n                                matches['matches'].append({\n                                    'type': 'regex',\n                                    'field': key,\n                                    'pattern': pattern['compiled'].pattern,\n                                    'description': pattern.get('description', '')\n                                })\n                else:  # Check specific field\n                    if field in event and isinstance(event[field], str):\n                        if pattern['compiled'].search(event[field]):\n                            matches['matches'].append({\n                                'type': 'regex',\n                                'field': field,\n                                'pattern': pattern['compiled'].pattern,\n                                'description': pattern.get('description', '')\n                            })\n            except Exception as e:\n                logger.error(f"Error applying regex pattern in rule {self.id}: {e}")\n        \n        # Check condition if specified (e.g., specific field values)\n        if self.condition:\n            try:\n                # Simple field-based condition evaluation\n                # This is a simplified version - in production, use a proper expression evaluator\n                # with proper sandboxing for security\n                condition_met = False\n                if '==' in self.condition:\n                    field, value = self.condition.split('==', 1)\n                    field = field.strip()\n                    value = value.strip(' \'"')\n                    if field in event and str(event[field]) == value:\n                        condition_met = True\n                \n                if not condition_met:\n                    return None\n                \n                matches['matches'].append({\n                    'type': 'condition',\n                    'condition': self.condition,\n                    'description': 'Matched condition'\n                })\n            except Exception as e:\n                logger.error(f"Error evaluating condition in rule {self.id}: {e}")\n        \n        # If we have any matches, return the match details\n        if matches['matches'] or (not self.yara_compiled and not self.compiled_regex and not self.condition):\n            return matches\n        \n        return None\n\nclass DetectionEngine:\n    """Main detection engine that manages and applies detection rules."""\n    \n    def __init__(self, rules_dir: Optional[str] = None, db_path: Optional[str] = None):\n        """Initialize the detection engine with rules from the specified directory."""\n        self.rules: Dict[str, DetectionRule] = {}\n        self.event_window: Dict[str, List[Dict]] = {}\n        self.db_path = db_path\n        self.rules_dir = rules_dir or 'rules'\n        self.load_rules()\n        self.metrics = {\n            'events_processed': 0,\n            'events_matched': 0,\n            'rules_triggered': {}\n        }\n    \n    def load_rules(self) -> None:\n        """Load detection rules from the rules directory."""\n        if not os.path.exists(self.rules_dir):\n            os.makedirs(self.rules_dir, exist_ok=True)\n            logger.warning(f"Rules directory {self.rules_dir} does not exist. Created empty directory.")\n            return\n        \n        rules_loaded = 0\n        for filename in os.listdir(self.rules_dir):\n            if filename.endswith('.json'):\n                try:\n                    with open(os.path.join(self.rules_dir, filename), 'r') as f:\n                        rule_data = json.load(f)\n                        if isinstance(rule_data, list):\n                            for r in rule_data:\n                                rule = DetectionRule.from_dict(r)\n                                self.rules[rule.id] = rule\n                                rules_loaded += 1\n                        else:\n                            rule = DetectionRule.from_dict(rule_data)\n                            self.rules[rule.id] = rule\n                            rules_loaded += 1\n                except Exception as e:\n                    logger.error(f"Error loading rule from {filename}: {e}")\n        \n        logger.info(f"Loaded {rules_loaded} detection rules from {self.rules_dir}")\n    \n    def process_event(self, event: Dict[str, Any]) -> List[Dict[str, Any]]:\n        """\n        Process an event through all enabled detection rules.\n        \n        Args:\n            event: The event to process\n            \n        Returns:\n            List of detection matches, or empty list if no matches\n        """\n        if not isinstance(event, dict):\n            logger.warning(f"Invalid event type: {type(event)}")\n            return []\n        \n        self.metrics['events_processed'] += 1\n        matches = []\n        \n        # Apply each rule to the event\n        for rule_id, rule in self.rules.items():\n            try:\n                match = rule.match(event)\n                if match:\n                    match['event'] = {k: v for k, v in event.items() if k != 'data'}\n                    matches.append(match)\n                    \n                    # Update metrics\n                    self.metrics['events_matched'] += 1\n                    if rule_id in self.metrics['rules_triggered']:\n                        self.metrics['rules_triggered'][rule_id] += 1\n                    else:\n                        self.metrics['rules_triggered'][rule_id] = 1\n                    \n                    logger.info(f"Rule {rule_id} matched event: {event.get('event_id', 'unknown')}")\n            except Exception as e:\n                logger.error(f"Error applying rule {rule_id}: {e}")\n        \n        # Handle threshold-based rules\n        threshold_matches = self._check_threshold_rules(event)\n        matches.extend(threshold_matches)\n        \n        # Store event in window for threshold-based rules\n        self._update_event_window(event)\n        \n        return matches\n    \n    def _update_event_window(self, event: Dict[str, Any]) -> None:\n        """Update the event window with the new event."""\n        now = time.time()\n        window_key = self._get_window_key(event)\n        \n        if window_key not in self.event_window:\n            self.event_window[window_key] = []\n        \n        # Add event to window\n        self.event_window[window_key].append({\n            'timestamp': now,\n            'event': event\n        })\n        \n        # Clean up old events\n        self._cleanup_event_window()\n    \n    def _get_window_key(self, event: Dict[str, Any]) -> str:\n        """Generate a key for grouping events in the window."""\n        # This is a simple implementation - in a real system, you might want to\n        # group by endpoint, user, process, etc.\n        endpoint_id = event.get('endpoint_id', 'unknown')\n        event_type = event.get('event_type', 'unknown')\n        return f"{endpoint_id}:{event_type}"\n    \n    def _cleanup_event_window(self) -> None:\n        """Remove old events from the window."""\n        now = time.time()\n        max_age = 3600  # 1 hour max age for events in window\n        \n        for key in list(self.event_window.keys()):\n            # Remove events older than max_age\n            self.event_window[key] = [\n                e for e in self.event_window[key]\n                if now - e['timestamp'] <= max_age\n            ]\n            \n            # Remove empty window entries\n            if not self.event_window[key]:\n                del self.event_window[key]\n    \n    def _check_threshold_rules(self, event: Dict[str, Any]) -> List[Dict[str, Any]]:\n        """Check for threshold-based rule matches."""\n        matches = []\n        window_key = self._get_window_key(event)\n        \n        if window_key not in self.event_window:\n            return matches\n        \n        # Get rules that might have threshold conditions\n        threshold_rules = [\n            r for r in self.rules.values()\n            if r.threshold is not None and r.time_window is not None\n        ]\n        \n        for rule in threshold_rules:\n            try:\n                # Count matching events in the time window\n                window_start = time.time() - rule.time_window\n                matching_events = [\n                    e for e in self.event_window[window_key]\n                    if e['timestamp'] >= window_start and\n                    self._event_matches_rule(e['event'], rule)\n                ]\n                \n                # Check if threshold is met\n                if len(matching_events) >= rule.threshold:\n                    match = {\n                        'rule_id': rule.id,\n                        'rule_name': rule.name,\n                        'severity': rule.severity,\n                        'timestamp': datetime.utcnow().isoformat(),\n                        'matches': [{\n                            'type': 'threshold',\n                            'count': len(matching_events),\n                            'threshold': rule.threshold,\n                            'time_window': rule.time_window,\n                            'description': f"Threshold of {rule.threshold} events in {rule.time_window} seconds exceeded"\n                        }],\n                        'events': matching_events\n                    }\n                    matches.append(match)\n                    \n                    # Update metrics\n                    if rule.id in self.metrics['rules_triggered']:\n                        self.metrics['rules_triggered'][rule.id] += 1\n                    else:\n                        self.metrics['rules_triggered'][rule.id] = 1\n                    \n                    logger.info(f"Threshold rule {rule.id} triggered with {len(matching_events)} events")\n            except Exception as e:\n                logger.error(f"Error checking threshold rule {rule.id}: {e}")\n        \n        return matches\n    \n    def _event_matches_rule(self, event: Dict[str, Any], rule: DetectionRule) -> bool:\n        """Check if an event matches a rule's basic conditions."""\n        # Check event type\n        if rule.event_types and event.get('event_type') not in rule.event_types:\n            return False\n        \n        # Check condition if specified\n        if rule.condition:\n            try:\n                # This is a simplified condition check\n                if '==' in rule.condition:\n                    field, value = rule.condition.split('==', 1)\n                    field = field.strip()\n                    value = value.strip(' \'"')\n                    if field not in event or str(event[field]) != value:\n                        return False\n            except Exception:\n                return False\n        \n        return True\n    \n    def get_metrics(self) -> Dict[str, Any]:\n        """Get detection engine metrics."""\n        return {\n            'rules_loaded': len(self.rules),\n            'events_processed': self.metrics['events_processed'],\n            'events_matched': self.metrics['events_matched'],\n            'rules_triggered': len(self.metrics['rules_triggered']),\n            'top_rules': sorted(\n                self.metrics['rules_triggered'].items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:10]  # Top 10 rules by trigger count\n        }\n\n# Example usage\nif __name__ == "__main__":\n    # Create a sample rule\n    sample_rule = DetectionRule(\n        id="suspicious_process_001",\n        name="Suspicious Process Execution",\n        description="Detects execution of suspicious processes",\n        severity="high",\n        event_types=["process_start"],\n        regex_patterns=[\n            {\n                "pattern": r"(powershell|cmd|wscript|cscript)\\.exe.*\-enc(odedcommand)?",\n                "field": "command_line",\n                "description": "Suspicious command line with encoded command"\n            }\n        ],\n        condition="parent_process_name == 'explorer.exe'"\n    )\n    \n    # Create detection engine\n    engine = DetectionEngine()\n    \n    # Add the sample rule\n    engine.rules[sample_rule.id] = sample_rule\n    \n    # Test event\n    test_event = {\n        "event_id": "12345",\n        "event_type": "process_start",\n        "timestamp": datetime.utcnow().isoformat(),\n        "endpoint_id": "endpoint-001",\n        "process_name": "powershell.exe",\n        "command_line": "powershell -enc UwB0AGEAcgB0AC0AUAByAG8AYwBlAHMAcwAgAG4Ab3RlcGFkAA==",\n        "parent_process_name": "explorer.exe",\n        "user": "DOMAIN\\user"\n    }\n    \n    # Process the event\n    matches = engine.process_event(test_event)\n    print(f"Detection matches: {json.dumps(matches, indent=2)}")\n    print(f"Metrics: {json.dumps(engine.get_metrics(), indent=2)}")
