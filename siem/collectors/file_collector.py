""\nFile-based log collector for SIEM.\nCollects logs from files and directories.\n"""\nimport os\nimport time\nimport json\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional, Set, Tuple\nfrom datetime import datetime\nimport glob\n\nfrom .base import BaseCollector\n\nclass FileCollector(BaseCollector):\n    """Collects logs from files and directories."""\n    \n    def _setup(self) -> None:\n        """Set up the file collector."""\n        self.config.setdefault('paths', ['/var/log'])\n        self.config.setdefault('file_patterns', ['*.log'])\n        self.config.setdefault('recursive', True)\n        self.config.setdefault('encoding', 'utf-8')\n        self.config.setdefault('read_from_beginning', False)\n        \n        # Track file positions for each file\n        self.file_positions: Dict[str, int] = {}\n        self.active_files: Set[str] = set()\n        \n        # Load previous positions if available\n        self._load_positions()\n    \n    def _load_positions(self) -> None:\n        """Load file positions from disk."""\n        try:\n            pos_file = self.config.get('position_file', 'file_positions.json')\n            if os.path.exists(pos_file):\n                with open(pos_file, 'r') as f:\n                    self.file_positions = json.load(f)\n        except Exception as e:\n            self.logger.warning(f"Failed to load file positions: {e}")\n    \n    def _save_positions(self) -> None:\n        """Save current file positions to disk."""\n        try:\n            pos_file = self.config.get('position_file', 'file_positions.json')\n            with open(pos_file, 'w') as f:\n                json.dump(self.file_positions, f)\n        except Exception as e:\n            self.logger.error(f"Failed to save file positions: {e}")\n    \n    def _get_files(self) -> List[str]:\n        """Get list of files to monitor."""\n        files = set()\n        \n        for path in self.config['paths']:\n            if os.path.isfile(path):\n                files.add(os.path.abspath(path))\n            elif os.path.isdir(path):\n                for pattern in self.config['file_patterns']:\n                    pattern_path = os.path.join(path, '**' if self.config['recursive'] else '', pattern)\n                    files.update(\n                        os.path.abspath(f) for f in glob.glob(pattern_path, recursive=self.config['recursive'])\n                        if os.path.isfile(f)\n                    )\n        \n        return sorted(files)\n    \n    def _read_file_changes(self, file_path: str) -> Tuple[List[Dict[str, Any]], int]:\n        """Read new lines from a file since last read position.\n        \n        Returns:\n            Tuple of (list of log entries, new file position)\n        """\n        entries = []\n        current_pos = self.file_positions.get(file_path, 0)\n        \n        try:\n            # Check if file was rotated\n            if os.path.getsize(file_path) < current_pos:\n                self.logger.info(f"File {file_path} appears to have been rotated")\n                current_pos = 0\n            \n            # Read new lines\n            with open(file_path, 'r', encoding=self.config['encoding'], errors='replace') as f:\n                f.seek(current_pos)\n                \n                for line in f:\n                    try:\n                        entry = self._parse_line(line.strip())\n                        if entry:\n                            entries.append(entry)\n                    except Exception as e:\n                        self.logger.error(f"Error parsing line in {file_path}: {e}")\n                \n                new_pos = f.tell()\n                \n            return entries, new_pos\n            \n        except (IOError, OSError) as e:\n            self.logger.error(f"Error reading file {file_path}: {e}")\n            return [], current_pos\n    \n    def _parse_line(self, line: str) -> Optional[Dict[str, Any]]:\n        """Parse a single log line into a structured format.\n        \n        Args:\n            line: Raw log line\n            \n        Returns:\n            Parsed log entry or None if line should be skipped\n        """\n        if not line.strip():  # Skip empty lines\n            return None\n            \n        # This is a basic implementation - should be customized per log format\n        return {\n            "@timestamp": datetime.utcnow().isoformat() + "Z",\n            "message": line,\n            "log": {\n                "file": {\n                    "path": self.config.get('current_file', 'unknown')\n                }\n            }\n        }\n    \n    def collect(self) -> List[Dict[str, Any]]:\n        """Collect logs from all monitored files."""\n        all_entries = []\n        current_files = self._get_files()\n        \n        # Check for new files and update active files\n        self.active_files.update(current_files)\n        \n        # Process each file\n        for file_path in current_files:\n            try:\n                if not os.path.exists(file_path):\n                    self.logger.debug(f"File not found, skipping: {file_path}")\n                    continue\n                    \n                # Set current file for context in _parse_line\n                self.config['current_file'] = file_path\n                \n                # Read new entries\n                entries, new_pos = self._read_file_changes(file_path)\n                if entries:\n                    all_entries.extend(entries)\n                    self.file_positions[file_path] = new_pos\n                \n            except Exception as e:\n                self.logger.error(f"Error processing file {file_path}: {e}")\n        \n        # Save positions periodically\n        if all_entries:\n            self._save_positions()\n        \n        return all_entries\n    \n    def start(self) -> None:\n        """Start the collector."""\n        super().start()\n        self.logger.info(f"Monitoring {len(self._get_files())} files for changes")\n    \n    def stop(self) -> None:\n        """Stop the collector and save positions."""\n        self._save_positions()\n        super().stop()
